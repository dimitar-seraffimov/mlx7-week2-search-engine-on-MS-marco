{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "with open('dataprep/ms_marco_combined/vocab_tkn/tkn_words_to_ids.pkl', 'rb') as f:\n",
    "    vocab_to_int = pickle.load(f)\n",
    "with open('dataprep/ms_marco_combined/vocab_tkn/tkn_ids_to_words.pkl', 'rb') as f:\n",
    "    int_to_vocab = pickle.load(f)\n",
    "\n",
    "# get special token IDs\n",
    "PAD_ID = vocab_to_int.get('<PAD>', 0)\n",
    "UNK_ID = vocab_to_int.get('<UNK>', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 79004, Val 9875, Test 9876\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(\"dataprep/ms_marco_combined/train.parquet\")\n",
    "val_df   = pd.read_parquet(\"dataprep/ms_marco_combined/validation.parquet\")\n",
    "test_df  = pd.read_parquet(\"dataprep/ms_marco_combined/test.parquet\")\n",
    "print(f\"Train {len(train_df)}, Val {len(val_df)}, Test {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> list[str]:\n",
    "    text = text.lower()\n",
    "    subs = {\n",
    "      r\"\\.\": \" <PERIOD> \",\n",
    "      r\",\":  \" <COMMA> \",\n",
    "      r'\"':  \" <QUOTATION_MARK> \",\n",
    "      r\";\":  \" <SEMICOLON> \",\n",
    "      r\"!\":  \" <EXCLAMATION_MARK> \",\n",
    "      r\"\\?\": \" <QUESTION_MARK> \",\n",
    "      r\"\\(\": \" <LEFT_PAREN> \",\n",
    "      r\"\\)\": \" <RIGHT_PAREN> \",\n",
    "      r\"--\": \" <HYPHENS> \",\n",
    "      r\":\":  \" <COLON> \",\n",
    "    }\n",
    "    for p, tok in subs.items():\n",
    "        text = re.sub(p, tok, text)\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_ids(text: str) -> list[int]:\n",
    "    return [\n",
    "        vocab_to_int.get(w, UNK_ID)\n",
    "        for w in preprocess(text)\n",
    "        if w  # skip empty tokens\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: avg q 6.1, p 83.2, n 80.4\n",
      "validation: avg q 6.0, p 83.2, n 80.0\n",
      "test: avg q 6.1, p 83.1, n 80.4\n"
     ]
    }
   ],
   "source": [
    "for df, name in [(train_df, \"train\"), (val_df, \"validation\"), (test_df, \"test\")]:\n",
    "    df[\"query_ids\"] = df[\"query\"].apply(text_to_ids)\n",
    "    df[\"pos_ids\"]   = df[\"positive_passage\"].apply(text_to_ids)\n",
    "    df[\"neg_ids\"]   = df[\"negative_passage\"].apply(text_to_ids)\n",
    "    print(f\"{name}: avg q {df['query_ids'].str.len().mean():.1f}, \"\n",
    "          f\"p {df['pos_ids'].str.len().mean():.1f}, \"\n",
    "          f\"n {df['neg_ids'].str.len().mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_pickle(\"dataprep/ms_marco_combined/tokenised/train_tokenised.pkl\")\n",
    "val_df.to_pickle(  \"dataprep/ms_marco_combined/tokenised/validation_tokenised.pkl\")\n",
    "test_df.to_pickle( \"dataprep/ms_marco_combined/tokenised/test_tokenised.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
